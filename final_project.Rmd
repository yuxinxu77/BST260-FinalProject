---
title: "BST260 Final Project"
author: "Junyi Guo"
date: "12/3/2020"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

# Data Preprocessing
```{r}
library(SASxport)
library(dplyr)
library(tidyverse)
library(ggcorrplot)
# data_dir <- "./data"
# setwd(data_dir)
```

## Diet Data Preprocessing
```{r}
# read in datasets
diet_1 <- read.xport('./data/DR1TOT_J.XPT')
diet_2 <- read.xport('./data/DR2TOT_J.XPT')
dat_t <- read.xport("./data/DIQ_J.XPT")
```

```{r}
# select useful columns and rename column names
diet_1 <- diet_1 %>% select(SEQN, DR1TKCAL, DR1TCARB, DR1TSUGR, DR1TTFAT, DR1TSODI) %>% rename('energy1' = 'DR1TKCAL', 'carbonhydrate1' = 'DR1TCARB', 'total_sugar1' = 'DR1TSUGR', 'total_fat1' = 'DR1TTFAT', 'sodium1' = 'DR1TSODI')
diet_2 <- diet_2 %>% select(SEQN, DR2TKCAL, DR2TCARB, DR2TSUGR, DR2TTFAT, DR2TSODI) %>% rename('energy2' = 'DR2TKCAL', 'carbonhydrate2' = 'DR2TCARB', 'total_sugar2' = 'DR2TSUGR', 'total_fat2' = 'DR2TTFAT', 'sodium2' = 'DR2TSODI')
dat_t <- dat_t %>% select(SEQN, DIQ010) %>% rename('diabetes' = 'DIQ010') %>% drop_na()

# now we can go ahead and full_join diet_1 and diet_2
dat <- full_join(diet_1, diet_2, by = 'SEQN')

# I decide to use the mean value of the two days if data from both date exist,
# use the value of one day if only data from that day exist,
# and delete the rows with all empty values except for id column.

dat <- dat %>% mutate(energy = ifelse((!is.na(energy1)) & (!is.na(energy2)), (energy1 + energy2)/2.0, ifelse(is.na(energy1), energy2, energy1)))
dat <- dat %>% mutate(carbonhydrate = ifelse((!is.na(carbonhydrate1)) & (!is.na(carbonhydrate2)), (carbonhydrate1 + carbonhydrate2)/2.0, ifelse(is.na(carbonhydrate1), carbonhydrate2, carbonhydrate1)))
dat <- dat %>% mutate(total_sugar = ifelse((!is.na(total_sugar1)) & (!is.na(total_sugar2)), (total_sugar1 + total_sugar2)/2.0, ifelse(is.na(total_sugar1), total_sugar2, total_sugar1)))
dat <- dat %>% mutate(total_fat = ifelse((!is.na(total_fat1)) & (!is.na(total_fat2)), (total_fat1 + total_fat2)/2.0, ifelse(is.na(total_fat1), total_fat2, total_fat1)))
dat <- dat %>% mutate(sodium = ifelse((!is.na(sodium1)) & (!is.na(sodium2)), (sodium1 + sodium2)/2.0, ifelse(is.na(sodium1), sodium2, sodium1)))

dat <- dat %>% select(SEQN, energy, carbonhydrate, total_sugar, total_fat, sodium) %>% drop_na()

# now dat only has 7495 rows, less than the original 8704 rows by 1209 rows
# that's exactly the expected number of empty rows

dat <- inner_join(dat,dat_t, by = 'SEQN')
dat <- dat %>% filter(diabetes == 1 | diabetes == 2)
```

## Demographic Data Preprocessing
```{r}
demo <- read.xport("./data/DEMO_J.XPT")
demo_clean <- demo %>% select(SEQN, DMDEDUC2, DMDMARTL, INDFMIN2, INDFMPIR, 
                              RIAGENDR, RIDAGEYR, RIDRETH3) %>%
                        rename(highest_edu = DMDEDUC2, marital_status = DMDMARTL, 
                               total_family_income = INDFMIN2, income_vs_poverty = INDFMPIR, 
                               gender = RIAGENDR, age = RIDAGEYR, race = RIDRETH3)

# Assgin marital status with values 77-Refused, 99-Don't Know, and NA to 0-Not Specified
demo_clean <- demo_clean %>% mutate(marital_status = 
                                     ifelse(marital_status == 77 | marital_status == 99 | is.na(marital_status) == TRUE, 0, marital_status))
# Drop any rows with NULL values in total_family_income, income_vs_poverty, household_income, highest_edu
demo_clean <- demo_clean %>% filter(is.na(total_family_income) != TRUE 
                                    & is.na(income_vs_poverty) != TRUE 
                                    & is.na(highest_edu) != TRUE)
summary(demo_clean)
# Join demographics data with other data and drop any rows with NULL values
# 5690 observation left
data <- left_join(demo_clean, dat, by = "SEQN") %>% drop_na()

```

## Examination Data Preprocessing
```{r}
# Add BMI to the cleaned data and drop any rows with NULL values
# 5631 observation left
exam <- read.xport("./data/BMX_J.XPT")
data <- left_join(data, exam %>% select(SEQN, BMXBMI), by = "SEQN") %>% 
                    rename(BMI = BMXBMI) %>% 
                    drop_na()
```

## Lab Data Preprocessing
```{r}
# Add HDL_Cholesterol to the cleaned data and drop any rows with NULL values
# 5205 observation left
data$SEQN <- as.numeric(data$SEQN)
lab3 <- read.xport("./data/HDL_J.XPT")
lab3$SEQN <- as.numeric(lab3$SEQN)
data <- left_join(data, lab3 %>% select(SEQN, LBDHDD), by = "SEQN") %>% 
  rename(HDL_Cholesterol = LBDHDD) %>% 
  drop_na()
```

## Reassign Diabetes value
```{r}
#revalue "no diabetes" from 2 to 0
data$diabetes[data$diabetes==2]<-0
```

## Remove extremely infrequent categorical value
```{r}
data <- data %>% filter(highest_edu != 7 & highest_edu != 9 & marital_status != 0)
```


# Data Visualization
## Pie Chart
```{r}
#pie chart
pie_chart<- function(diab, cat, level) {
  pie_dat <- as.data.frame(table(data %>% filter(diabetes ==diab)%>%select(cat)))%>%rename(cat = Var1)
  pie_dat $ cat<- level
  ggplot(pie_dat, aes(x="", y=Freq, fill=cat)) +
    geom_bar(stat="identity", width=1) +
    coord_polar("y", start=0)
}

cats <- c("highest_edu", "marital_status", "gender", "race", "total_family_income")
level_edu <- c("Less than 9th grade","9-11th grade (Includes 12th grade with no diploma)",
               "High school graduate/GED or equivalent",	
               "Some college or AA degree",
               "College graduate or above")
level_marital <- c("Married", "Widowed", "Divorced", "Separated", "Never married",
                   "Living with partner")	
level_gender <- c("Male", "Female")

level_race <- c("Mexican American",		
                "Other Hispanic",	
                "Non-Hispanic White",	
                "Non-Hispanic Black",	
                "Non-Hispanic Asian",	
                "Other Race - Including Multi-Racial")
level_income <- c("$0 to $4,999", 
                  "$5,000 to $9,999", 
                  "$10,000 to $14,999",
                  "$15,000 to $19,999",
                  "$20,000 to $24,999", 
                  "$25,000 to $34,999", 
                  "$35,000 to $44,999", 
                  "$45,000 to $54,999", 
                  "$55,000 to $64,999", 
                  "$65,000 to $74,999", 
                  "$75,000 to $99,999", 
                  "$100,000 and Over")

###### Questions ##########
pie_chart(0, "highest_edu", level_edu)
pie_chart(1,"highest_edu", level_edu[-6])
pie_chart(0, "marital_status", level_marital)
pie_chart(1, "marital_status", level_marital[-7])
pie_chart(0, "gender", level_gender)
pie_chart(1, "gender", level_gender)
pie_chart(0, "race", level_race)
pie_chart(1, "race", level_race)
pie_chart(0, "total_family_income", level_income)
pie_chart(1, "total_family_income", level_income)
```

## Back to Back Histogram
### Age
```{r}
# back to back histogram: age
level_age <- c("[0-10)","[10-20)", "[20-30)", "[30-40)", "[40-50)", "[50-60)","[60-70)", "[70-80)","[80-90)", "[90-100)")
d_age <- data %>% select(age, diabetes) %>% 
  mutate(age_tag = case_when(
    age < 10 ~ level_age[1],
    age >= 10 & age < 20 ~ level_age[2],
    age >= 20 & age < 30 ~ level_age[3],
    age >= 30 & age < 40 ~ level_age[4],
    age >= 40 & age < 50 ~ level_age[5],
    age >= 50 & age < 60 ~ level_age[6],
    age >= 60 & age < 70 ~ level_age[7],
    age >= 70 & age < 80 ~ level_age[8],
    age >= 80 & age < 90 ~ level_age[9])) %>% 
  group_by(age_tag, diabetes) %>% 
  summarise(percentage = n(), .groups = "drop") %>% 
  mutate(percentage = ifelse(diabetes == 1, -percentage/sum(data$diabetes == 1), percentage/sum(data$diabetes == 0))) %>% 
  mutate(diabetes = ifelse(diabetes == 0, "No Diabetes", "Has Diabetes"))

# plot
age <- d_age %>% 
  ggplot(aes(x = age_tag, y = percentage, group = diabetes, fill = diabetes)) +
  geom_bar(stat = "identity", width = 0.75) +
  coord_flip() +
  scale_x_discrete(limits = level_age) +
  # another trick!
  scale_y_continuous(limits = c(-1, 1),
                     breaks = seq(-1, 1, 0.1), 
                     labels = abs(seq(-1 , 1, 0.1))) +
  labs(x = "Age (years)", y = "Percentage", title = "Age-Diabetes Distribution Comparison") +
  theme(legend.position = "bottom",
        legend.title = element_blank(),
        plot.title = element_text(hjust = 0.5),
        panel.background = element_rect(fill =  "grey90")) +
  scale_fill_manual(values=c("red", "blue"),
                    name="",
                    breaks=c("Has Diabetes", "No Diabetes"),
                    labels=c("Has Diabetes", "No Diabetes")) 

print(age)
```

### Energy
```{r}
# back to back histogram: energy
level_energy <- c("[0-1000)","[1000-2000)", "[2000-3000)", "[3000-4000)", "[4000-5000)", "[5000-6000)","[6000-7000)", "[7000-8000)","[8000-9000)")
d_energy <- data %>% select(energy, diabetes) %>% 
  mutate(energy_tag = case_when(
    energy < 1000 ~ level_energy[1],
    energy >= 1000 & energy < 2000 ~ level_energy[2],
    energy >= 2000 & energy < 3000 ~ level_energy[3],
    energy >= 3000 & energy < 4000 ~ level_energy[4],
    energy >= 4000 & energy < 5000 ~ level_energy[5],
    energy >= 5000 & energy < 6000 ~ level_energy[6],
    energy >= 6000 & energy < 7000 ~ level_energy[7],
    energy >= 7000 & energy < 8000 ~ level_energy[8],
    energy >= 8000 & energy < 9000 ~ level_energy[9])) %>% 
  group_by(energy_tag, diabetes) %>% 
  summarise(percentage = n(), .groups = "drop") %>% 
  mutate(percentage = ifelse(diabetes == 1, -percentage/sum(data$diabetes == 1), percentage/sum(data$diabetes == 0))) %>% 
  mutate(diabetes = ifelse(diabetes == 0, "No Diabetes", "Has Diabetes"))

# plot
energy <- d_energy %>% 
  ggplot(aes(x = energy_tag, y = percentage, group = diabetes, fill = diabetes)) +
  geom_bar(stat = "identity", width = 0.75) +
  coord_flip() +
  scale_x_discrete(limits = level_energy) +
  # another trick!
  scale_y_continuous(limits = c(-1, 1),
                     breaks = seq(-1, 1, 0.1), 
                     labels = abs(seq(-1 , 1, 0.1))) +
  labs(x = "Energy (kcal)", y = "Percentage", title = "Daily Energy Intake - Diabetes Distribution Comparison") +
  theme(legend.position = "bottom",
        legend.title = element_blank(),
        plot.title = element_text(hjust = 0.5),
        panel.background = element_rect(fill =  "grey90")) +
  scale_fill_manual(values=c("red", "blue"),
                    name="",
                    breaks=c("Has Diabetes", "No Diabetes"),
                    labels=c("Has Diabetes", "No Diabetes")) 

print(energy)
```

### Carbonhydrate
```{r}
# back to back histogram: carbonhydrate
level_carb <- c("[0-100)","[100-200)", "[200-300)", "[300-400)", "[400-500)", "[500-600)","[600-700)", "[700-800)","[800-900)", "[900-1000)", "[1000-1100)")
d_carb <- data %>% select(carbonhydrate, diabetes) %>% 
  mutate(carb_tag = case_when(
    carbonhydrate < 100 ~ level_carb[1],
    carbonhydrate >= 100 & carbonhydrate < 200 ~ level_carb[2],
    carbonhydrate >= 200 & carbonhydrate < 300 ~ level_carb[3],
    carbonhydrate >= 300 & carbonhydrate < 400 ~ level_carb[4],
    carbonhydrate >= 400 & carbonhydrate < 500 ~ level_carb[5],
    carbonhydrate >= 500 & carbonhydrate < 600 ~ level_carb[6],
    carbonhydrate >= 600 & carbonhydrate < 700 ~ level_carb[7],
    carbonhydrate >= 700 & carbonhydrate < 800 ~ level_carb[8],
    carbonhydrate >= 800 & carbonhydrate < 900 ~ level_carb[9],
    carbonhydrate >= 900 & carbonhydrate < 1000 ~ level_carb[10],
    carbonhydrate >= 1000 & carbonhydrate < 1100 ~ level_carb[11])) %>% 
  group_by(carb_tag, diabetes) %>% 
  summarise(percentage = n(), .groups = "drop") %>% 
  mutate(percentage = ifelse(diabetes == 1, -percentage/sum(data$diabetes == 1), percentage/sum(data$diabetes == 0))) %>% 
  mutate(diabetes = ifelse(diabetes == 0, "No Diabetes", "Has Diabetes"))

# plot
carb <- d_carb %>% 
  ggplot(aes(x = carb_tag, y = percentage, group = diabetes, fill = diabetes)) +
  geom_bar(stat = "identity", width = 0.75) +
  coord_flip() +
  scale_x_discrete(limits = level_carb) +
  # another trick!
  scale_y_continuous(limits = c(-1, 1),
                     breaks = seq(-1, 1, 0.1), 
                     labels = abs(seq(-1 , 1, 0.1))) +
  labs(x = "Carbonhydrate (gm)", y = "Percentage", title = "Daily Carbonhydrate Intake - Diabetes Distribution Comparison") +
  theme(legend.position = "bottom",
        legend.title = element_blank(),
        plot.title = element_text(hjust = 0.5),
        panel.background = element_rect(fill =  "grey90")) +
  scale_fill_manual(values=c("red", "blue"),
                    name="",
                    breaks=c("Has Diabetes", "No Diabetes"),
                    labels=c("Has Diabetes", "No Diabetes")) 

print(carb)
```

### Sugar
```{r}
# back to back histogram: sugar
level_sugar <- c("[0-100)","[100-200)", "[200-300)", "[300-400)", "[400-500)", "[500-600)","[600-700)", "[700-800)","[800-900)", "[900-1000)")
d_sugar <- data %>% select(total_sugar, diabetes) %>% 
  mutate(sugar_tag = case_when(
    total_sugar < 100 ~ level_sugar[1],
    total_sugar >= 100 & total_sugar < 200 ~ level_sugar[2],
    total_sugar >= 200 & total_sugar < 300 ~ level_sugar[3],
    total_sugar >= 300 & total_sugar < 400 ~ level_sugar[4],
    total_sugar >= 400 & total_sugar < 500 ~ level_sugar[5],
    total_sugar >= 500 & total_sugar < 600 ~ level_sugar[6],
    total_sugar >= 600 & total_sugar < 700 ~ level_sugar[7],
    total_sugar >= 700 & total_sugar < 800 ~ level_sugar[8],
    total_sugar >= 800 & total_sugar < 900 ~ level_sugar[9],
    total_sugar >= 900 & total_sugar < 1000 ~ level_sugar[10])) %>% 
  group_by(sugar_tag, diabetes) %>% 
  summarise(percentage = n(), .groups = "drop") %>% 
  mutate(percentage = ifelse(diabetes == 1, -percentage/sum(data$diabetes == 1), percentage/sum(data$diabetes == 0))) %>% 
  mutate(diabetes = ifelse(diabetes == 0, "No Diabetes", "Has Diabetes"))

# plot
sugar <- d_sugar %>% 
  ggplot(aes(x = sugar_tag, y = percentage, group = diabetes, fill = diabetes)) +
  geom_bar(stat = "identity", width = 0.75) +
  coord_flip() +
  scale_x_discrete(limits = level_sugar) +
  # another trick!
  scale_y_continuous(limits = c(-1, 1),
                     breaks = seq(-1, 1, 0.1), 
                     labels = abs(seq(-1 , 1, 0.1))) +
  labs(x = "Total Sugar (gm)", y = "Percentage", title = "Daily Sugar Intake - Diabetes Distribution Comparison") +
  theme(legend.position = "bottom",
        legend.title = element_blank(),
        plot.title = element_text(hjust = 0.5),
        panel.background = element_rect(fill =  "grey90")) +
  scale_fill_manual(values=c("red", "blue"),
                    name="",
                    breaks=c("Has Diabetes", "No Diabetes"),
                    labels=c("Has Diabetes", "No Diabetes")) 

print(sugar)
```

### Fat
```{r}
# back to back histogram: fat
level_fat <- c("[0-50)","[50-100)", "[100-150)", "[150-200)", "[200-250)", "[250-300)","[300-350)", "[350-400)")
d_fat <- data %>% select(total_fat, diabetes) %>% 
  mutate(fat_tag = case_when(
    total_fat < 50 ~ level_fat[1],
    total_fat >= 50 & total_fat < 100 ~ level_fat[2],
    total_fat >= 100 & total_fat < 150 ~ level_fat[3],
    total_fat >= 150 & total_fat < 200 ~ level_fat[4],
    total_fat >= 200 & total_fat < 250 ~ level_fat[5],
    total_fat >= 250 & total_fat < 300 ~ level_fat[6],
    total_fat >= 300 & total_fat < 350 ~ level_fat[7],
    total_fat >= 350 & total_fat < 400 ~ level_fat[8])) %>% 
  group_by(fat_tag, diabetes) %>% 
  summarise(percentage = n(), .group = "drop") %>% 
  mutate(percentage = ifelse(diabetes == 1, -percentage/sum(data$diabetes == 1), percentage/sum(data$diabetes == 0))) %>% 
  mutate(diabetes = ifelse(diabetes == 0, "No Diabetes", "Has Diabetes"))

# plot
fat <- d_fat %>% 
  ggplot(aes(x = fat_tag, y = percentage, group = diabetes, fill = diabetes)) +
  geom_bar(stat = "identity", width = 0.75) +
  coord_flip() +
  scale_x_discrete(limits = level_fat) +
  # another trick!
  scale_y_continuous(limits = c(-1, 1),
                     breaks = seq(-1, 1, 0.1), 
                     labels = abs(seq(-1 , 1, 0.1))) +
  labs(x = "Total Fat (gm)", y = "Percentage", title = "Daily Fat Intake - Diabetes Distribution Comparison") +
  theme(legend.position = "bottom",
        legend.title = element_blank(),
        plot.title = element_text(hjust = 0.5),
        panel.background = element_rect(fill =  "grey90")) +
  scale_fill_manual(values=c("red", "blue"),
                    name="",
                    breaks=c("Has Diabetes", "No Diabetes"),
                    labels=c("Has Diabetes", "No Diabetes")) 

print(fat)
```

### Sodium
```{r}
# back to back histogram: sodium
level_sodium <- c("[0-2000)","[2000-4000)", "[4000-6000)", "[6000-8000)", "[8000-10000)", "[10000-12000)","[12000-14000)", "[14000-16000)","[16000-18000)", "[18000-20000)", "[20000-22000)", "[22000-24000)", "[24000-26000)")
d_sodium <- data %>% select(sodium, diabetes) %>% 
  mutate(sodium_tag = case_when(
    sodium < 2000 ~ level_sodium[1],
    sodium >= 2000 & sodium < 4000 ~ level_sodium[2],
    sodium >= 4000 & sodium < 6000 ~ level_sodium[3],
    sodium >= 6000 & sodium < 8000 ~ level_sodium[4],
    sodium >= 8000 & sodium < 10000 ~ level_sodium[5],
    sodium >= 10000 & sodium < 12000 ~ level_sodium[6],
    sodium >= 12000 & sodium < 14000 ~ level_sodium[7],
    sodium >= 14000 & sodium < 16000 ~ level_sodium[8],
    sodium >= 16000 & sodium < 18000 ~ level_sodium[9],
    sodium >= 18000 & sodium < 20000 ~ level_sodium[10],
    sodium >= 20000 & sodium < 22000 ~ level_sodium[11],
    sodium >= 22000 & sodium < 24000 ~ level_sodium[12],
    sodium >= 24000 & sodium < 26000 ~ level_sodium[13])) %>% 
  group_by(sodium_tag, diabetes) %>% 
  summarise(percentage = n(), .group = "drop") %>% 
  mutate(percentage = ifelse(diabetes == 1, -percentage/sum(data$diabetes == 1), percentage/sum(data$diabetes == 0))) %>% 
  mutate(diabetes = ifelse(diabetes == 0, "No Diabetes", "Has Diabetes"))

# plot
sodium <- d_sodium %>% 
  ggplot(aes(x = sodium_tag, y = percentage, group = diabetes, fill = diabetes)) +
  geom_bar(stat = "identity", width = 0.75) +
  coord_flip() +
  scale_x_discrete(limits = level_sodium) +
  # another trick!
  scale_y_continuous(limits = c(-1, 1),
                     breaks = seq(-1, 1, 0.1), 
                     labels = abs(seq(-1 , 1, 0.1))) +
  labs(x = "Total Sodium (mg)", y = "Percentage", title = "Daily Sodium Intake - Diabetes Distribution Comparison") +
  theme(legend.position = "bottom",
        legend.title = element_blank(),
        plot.title = element_text(hjust = 0.5),
        panel.background = element_rect(fill =  "grey90")) +
  scale_fill_manual(values=c("red", "blue"),
                    name="",
                    breaks=c("Has Diabetes", "No Diabetes"),
                    labels=c("Has Diabetes", "No Diabetes")) 

print(sodium)
```

## Histogram
```{r}
# data %>% select(total_family_income, diabetes) %>%
#     mutate(total_family_income = as.numeric(total_family_income), diabetes = ifelse(diabetes == 1, "Diabetes", "No Diabetes")) %>%
#     ggplot(aes(x=total_family_income, color=diabetes, fill=diabetes)) +
#     geom_histogram(aes(y=..density..), position="identity", alpha=0.5, bins = 15) +
#     geom_density(alpha=0.6) +
#     scale_color_manual(values=c("#999999", "#E69F00", "#56B4E9"))+
#     scale_fill_manual(values=c("#999999", "#E69F00", "#56B4E9"))+
#     labs(title="Total Family Income",x="Total Family Income", y = "Density")+
#     theme_classic()
```

### Income vs Poverty
```{r}
mean_ip <- data %>% select(income_vs_poverty, diabetes) %>%
    mutate(diabetes = ifelse(diabetes == 1, "Diabetes", "No Diabetes")) %>%
    group_by(diabetes) %>%
    summarise(mean = mean(income_vs_poverty), .groups = "drop")

data %>% select(income_vs_poverty, diabetes) %>%
    mutate(diabetes = ifelse(diabetes == 1, "Diabetes", "No Diabetes")) %>%
    rename(Diabetes = diabetes) %>%
    ggplot(aes(x=income_vs_poverty, color=Diabetes, fill=Diabetes)) +
    geom_histogram(aes(y=..density..), position="identity", alpha=0.5, bins = 15) +
    geom_density(alpha=0.4) +
    geom_vline(data = mean_ip, aes(xintercept=mean, color=diabetes),
             linetype="dashed")+
    scale_color_manual(values=c("#999999", "#E69F00", "#56B4E9"))+
    scale_fill_manual(values=c("#999999", "#E69F00", "#56B4E9"))+
    labs(title="Ratio of Family Income to Poverty",x="Family Income Ratio", y = "Density")+
    theme_classic()
```
### BMI
```{r}
mean_bmi <- data %>% select(BMI, diabetes) %>%
    mutate(diabetes = ifelse(diabetes == 1, "Diabetes", "No Diabetes")) %>%
    group_by(diabetes) %>%
    summarise(mean = mean(BMI), .groups = "drop")

data %>% select(BMI, diabetes) %>%
    mutate(diabetes = ifelse(diabetes == 1, "Diabetes", "No Diabetes")) %>%
    rename(Diabetes = diabetes) %>%
    ggplot(aes(x=BMI, color=Diabetes, fill=Diabetes)) +
    geom_histogram(aes(y=..density..), position="identity", alpha=0.5, bins = 20) +
    geom_density(alpha=0.4) +
    geom_vline(data = mean_bmi, aes(xintercept=mean, color=diabetes),
             linetype="dashed")+
    scale_color_manual(values=c("#999999", "#E69F00", "#56B4E9"))+
    scale_fill_manual(values=c("#999999", "#E69F00", "#56B4E9"))+
    labs(title="Body Mass Index",x="Body Mass Index (kg/m**2)", y = "Density")+
    theme_classic()
```
### HDL_Cholesterol
```{r}
mean_cho <- data %>% select(HDL_Cholesterol, diabetes) %>%
    mutate(diabetes = ifelse(diabetes == 1, "Diabetes", "No Diabetes")) %>%
    group_by(diabetes) %>%
    summarise(mean = mean(HDL_Cholesterol), .groups = "drop")

data %>% select(HDL_Cholesterol, diabetes) %>%
    mutate(HDL_Cholesterol = as.numeric(HDL_Cholesterol), 
           diabetes = ifelse(diabetes == 1, "Diabetes", "No Diabetes")) %>%
    rename(Diabetes = diabetes) %>%
    ggplot(aes(x=HDL_Cholesterol, color=Diabetes, fill=Diabetes)) +
    geom_histogram(aes(y=..density..), position="identity", alpha=0.5, bins = 20) +
    geom_density(alpha=0.4) +
    geom_vline(data = mean_cho, aes(xintercept=mean, color=diabetes),
             linetype="dashed")+
    scale_color_manual(values=c("#999999", "#E69F00", "#56B4E9"))+
    scale_fill_manual(values=c("#999999", "#E69F00", "#56B4E9"))+
    labs(title="Direct HDL-Cholesterol",x="Direct HDL-Cholesterol (mg/dL)", y = "Density")+
    theme_classic()
```


## Correlation Plot
```{r}
#correlation plot
r <- cor(data, use="complete.obs")
ggcorrplot(r)
```

# Building Data Pipeline
## One-hot encoding
```{r}
library(mltools)
library(data.table)

data_onehot <- data %>% select(-c("SEQN")) %>% 
    mutate(total_family_income = ifelse(total_family_income == 14 | total_family_income == 15, 
                                        ifelse(total_family_income == 14, 11, 12), total_family_income)) %>%
    mutate(highest_edu = as.factor(highest_edu), 
           marital_status = as.factor(marital_status), 
           race = as.factor(race)) 
data_onehot <- one_hot(data.table(data_onehot))
data_onehot <- data_onehot %>% mutate(diabetes = as.factor(diabetes))
```

## Train-test split
```{r}
# data_0 <- data_onehot %>% filter(diabetes == 0)
# data_1 <- data_onehot %>% filter(diabetes == 1)
# data_0_sample <- sample_n(data_0, nrow(data_1))
# data_sample <- rbind(data_0_sample, data_1)
# 
# train_index <- createDataPartition(data_sample$diabetes, times = 1, p = 0.8, list = FALSE)
# train_set <- data_sample[train_index, ]
# test_set <- data_sample[-train_index, ]
# X_train <- train_set %>% select(-c(diabetes))
# y_train <- train_set$diabetes
# X_test <- test_set %>% select(-c(diabetes))
# y_test <- test_set$diabetes
```

```{r}
library(caret)
library(ROSE)
train_index <- createDataPartition(data_onehot$diabetes, times = 1, p = 0.8, list = FALSE)
train_set <- data_onehot[train_index, ]
train_balanced <- ovun.sample(diabetes ~ ., data = train_set, method = "over", N = 5108)$data
table(train_balanced$diabetes)

test_set <- data_onehot[-train_index, ]

# Unbalanced training data
X_train <- train_set %>% select(-c(diabetes))
y_train <- train_set$diabetes

# Balanced training data
X_train_balanced <- train_balanced %>% select(-c(diabetes))
y_train_balanced <- train_balanced$diabetes

X_test <- test_set %>% select(-c(diabetes))
y_test <- test_set$diabetes
```

```{r}
table(data$highest_edu)
table(data$marital_status)
table(data$gender)
table(data$race)
```

## PCA
```{r}
# Install the package if needed
# Run full PCA to select principle components
# install.packages("factoextra")
library(factoextra)
library("corrplot")
pca_full <- prcomp(X_train, scale = TRUE)
summary(pca_full)
fviz_eig(pca_full)
fviz_pca_var(pca_full,
             col.var = "contrib", # Color by contributions to the PC
             gradient.cols = c("#00AFBB", "#E7B800", "#FC4E07"),
             repel = TRUE     # Avoid text overlapping
             )

corrplot(get_pca(pca_full)$cos2, is.corr=FALSE)

```

```{r}
# Run pca on selected number of principle components
pca_part <- prcomp(X_train, scale = TRUE, rank. = 10)
summary(pca_part)
# Apply pca transform on both training set and test set
# Unbalanced training data
X_train_pca = data.frame(pca_part$x)
X_test_pca = data.frame(predict(pca_part, newdata = X_test))
```


```{r}
# Run pca on selected number of priciple components
pca_balanced_part <- prcomp(X_train_balanced, scale = TRUE, rank. = 10)
summary(pca_balanced_part)
# Apply pca transform on both training set and test set
# Unbalanced training data
X_train_balanced_pca = data.frame(pca_balanced_part$x)
X_test_balanced_pca = data.frame(predict(pca_balanced_part, newdata = X_test))
```


```{r}
#Convert target to factor
# y_train <- as.factor(y_train)
# y_test <- as.factor(y_test)
```


# Modeling
```{r}
# Runting: Boosting, RF
# Yuxin: SVM, KNN
# Jessie: Logistic Regression, Linear Regression
```

## Linear Regression
```{r}
# LR: not balanced, no pca
library(pROC)
train_regression <- cbind(X_train, y_train) %>% rename(diabetes = y_train)
glm_fit <- glm(diabetes ~ ., data = train_regression, family=binomial)
summary(glm_fit)
glm_predict_prob <- predict(glm_fit, X_test, type="response")
glm_predict <- ifelse(glm_predict_prob >= 0.1, 1, 0)
confusionMatrix(as.factor(glm_predict), as.factor(y_test), positive = "1")
roc_curve <- roc(y_test, glm_predict_prob, 
                 smoothed = TRUE,
                 # arguments for ci
                 ci=TRUE, ci.alpha=0.9, stratified=FALSE,
                 # arguments for plot
                 plot=TRUE, auc.polygon=TRUE, max.auc.polygon=TRUE, grid=TRUE,
                 print.auc=TRUE, show.thres=TRUE)
sensitivity_ci <- ci.se(roc_curve)
plot(sensitivity_ci, type="shape", col="lightblue")
```

```{r}
# LR: not balanced, no pca, cv
train_control <- trainControl(method = "cv", number = 10)
glm_cv <- train(diabetes ~ .,
               data = train_regression,
               trControl = train_control,
               method = "glm",
               family=binomial())

summary(glm_cv)
glm_predict_prob <- predict(glm_cv, X_test, type="prob")
glm_predict <- ifelse(glm_predict_prob >= 0.5, 1, 0)
glm_predict <- ifelse(glm_predict[, 1] == 1, 0, 1)
confusionMatrix(as.factor(glm_predict), as.factor(y_test), positive = "1")
roc_curve <- roc(y_test, glm_predict_prob[, 1], 
                 smoothed = TRUE,
                 # arguments for ci
                 ci=TRUE, ci.alpha=0.9, stratified=FALSE,
                 # arguments for plot
                 plot=TRUE, auc.polygon=TRUE, max.auc.polygon=TRUE, grid=TRUE,
                 print.auc=TRUE, show.thres=TRUE)
sensitivity_ci <- ci.se(roc_curve)
plot(sensitivity_ci, type="shape", col="lightblue")
```

```{r}
# LR: not balanced, with PCA
# library(pROC)
train_regression_pca <- cbind(X_train_pca, y_train) %>% rename(diabetes = y_train)
glm_fit_pca <- glm(diabetes ~ ., data = train_regression_pca, family=binomial)
summary(glm_fit_pca)
glm_predict_prob <- predict(glm_fit_pca, X_test_pca, type="response")
glm_predict <- ifelse(glm_predict_prob >= 0.5, 1, 0)
confusionMatrix(as.factor(glm_predict), as.factor(y_test), positive = "1")
roc_curve <- roc(y_test, glm_predict_prob, 
                 smoothed = TRUE,
                 # arguments for ci
                 ci=TRUE, ci.alpha=0.9, stratified=FALSE,
                 # arguments for plot
                 plot=TRUE, auc.polygon=TRUE, max.auc.polygon=TRUE, grid=TRUE,
                 print.auc=TRUE, show.thres=TRUE)
sensitivity_ci <- ci.se(roc_curve)
plot(sensitivity_ci, type="shape", col="lightblue")
```

```{r}
# LR: balanced, not PCA
# library(pROC)
train_regression_balanced <- cbind(X_train_balanced, y_train_balanced) %>% rename(diabetes = y_train_balanced)
glm_fit_balanced <- glm(diabetes ~ ., data = train_regression_balanced, family=binomial)
summary(glm_fit_balanced)
glm_predict_prob <- predict(glm_fit_balanced, X_test, type="response")
glm_predict <- ifelse(glm_predict_prob >= 0.37, 1, 0)
confusionMatrix(as.factor(glm_predict), as.factor(y_test), positive = "1")
roc_curve <- roc(y_test, glm_predict_prob, 
                 smoothed = TRUE,
                 # arguments for ci
                 ci=TRUE, ci.alpha=0.9, stratified=FALSE,
                 # arguments for plot
                 plot=TRUE, auc.polygon=TRUE, max.auc.polygon=TRUE, grid=TRUE,
                 print.auc=TRUE, show.thres=TRUE)
sensitivity_ci <- ci.se(roc_curve)
plot(sensitivity_ci, type="shape", col="lightblue")

```

```{r}
#function to plot roc curve
plot_roc <- function(pre){
roc_curve <- roc(y_test, as.numeric(pre),
                 smoothed = TRUE,
                 # arguments for ci
                 ci=TRUE, ci.alpha=0.9, stratified=FALSE,
                 # arguments for plot
                 plot=TRUE, auc.polygon=TRUE, max.auc.polygon=TRUE, grid=TRUE,
                 print.auc=TRUE, show.thres=TRUE)
sensitivity_ci <- ci.se(roc_curve)
plot(sensitivity_ci, type="shape", col="lightblue")
}
```


```{r}
# LR: balanced, with PCA
# library(pROC)
train_regression_balanced_pca <- cbind(X_train_balanced_pca, y_train_balanced) %>% rename(diabetes = y_train_balanced)
glm_fit_balanced_pca <- glm(diabetes ~ ., data = train_regression_balanced_pca, family=binomial)
summary(glm_fit_balanced_pca)
glm_predict_prob <- predict(glm_fit_balanced_pca, X_test_balanced_pca, type="response")
glm_predict <- ifelse(glm_predict_prob >= 0.37, 1, 0)
confusionMatrix(as.factor(glm_predict), as.factor(y_test), positive = "1")
roc_curve <- roc(y_test, glm_predict_prob, 
                 smoothed = TRUE,
                 # arguments for ci
                 ci=TRUE, ci.alpha=0.9, stratified=FALSE,
                 # arguments for plot
                 plot=TRUE, auc.polygon=TRUE, max.auc.polygon=TRUE, grid=TRUE,
                 print.auc=TRUE, show.thres=TRUE)
sensitivity_ci <- ci.se(roc_curve)
plot(sensitivity_ci, type="shape", col="lightblue")
```

#RF
```{r}
library(randomForest)
library(ROSE)
#No PCA, not balanced: TERRIBLE
tr <- trainControl(method = "cv", number = 10)
rf_classifier = randomForest(x = X_train, y = y_train, xtest = X_test, ytest=y_test, ntree=100, mtry=4, importance=TRUE, keep.forest=TRUE, trControl = tr)
rf_classifier
pre = predict(rf_classifier, X_test, type = "response")
confusionMatrix(as.factor(pre), as.factor(y_test))
plot_roc(as.numeric(pre))

```

```{r}
library(randomForest)
library(ROSE)
#PCA, balanced: 
tr <- trainControl(method = "cv", number = 10)

#plot_roc(as.numeric(pre))

```

```{r}
#best rf for No PCA, balanced GOOD
rf_classifier = randomForest(x = X_train_balanced, y = y_train_balanced, xtest = X_test, ytest=y_test, ntree=100, mtry=5, importance=TRUE, keep.forest=TRUE, trControl = tr, nodesize = 5, maxnodes = 15) #maxnodes is the most important
#rf_classifier
pre = predict(rf_classifier, X_test, type = "response")
print(confusionMatrix(as.factor(pre), as.factor(y_test)))
plot_roc(as.numeric(pre))
```

```{r}
#PCA, not balanced: emmm
tr <- trainControl(method = "cv", number = 10)
rf_classifier = randomForest(x = X_train_pca, y = y_train, xtest = X_test_pca, ytest=y_test, ntree=100, mtry=5, importance=TRUE, keep.forest=TRUE, trControl = tr, nodesize = 5, )
#rf_classifier
pre = predict(rf_classifier, X_test_pca, type = "response")
print(confusionMatrix(as.factor(pre), as.factor(y_test)))


```

```{r}
#pca balanced GOOD
rf_classifier = randomForest(x = X_train_balanced_pca, y = y_train_balanced, xtest = X_test_balanced_pca, ytest=y_test, ntree=100, importance=TRUE, keep.forest=TRUE, trControl = tr, maxnodes = 15)
#rf_classifier
pre = predict(rf_classifier, X_test_balanced_pca, type = "response")
print(confusionMatrix(as.factor(pre), as.factor(y_test)))
plot_roc(as.numeric(pre))
```

# Boosting
```{r}
library(gbm)
#no pca not balanced GOOD
data_nn = X_train
class(y_train)
data_nn$y = y_train

boost=gbm(y ~.,
              data = data_nn,
              distribution = "multinomial",
              cv.folds = 10,
              shrinkage = .1,
              n.minobsinnode = 20,
              n.trees = 150) #reduce n.trees to increase sensitivity
pre <- predict(boost, newdata = X_test, type = "response", n.trees = 200)
pred <- pre[,,1][,1]
y_pred <- ifelse(as.numeric(pred)>0.85,0,1)
confusionMatrix(as.factor(y_pred), as.factor(y_test))
plot_roc(as.numeric(y_pred))
```

```{r}
#no pca, balanced GOOD
data_nb = X_train_balanced
data_nb$y = y_train_balanced

boost=gbm(y ~.,
              data = data_nb,
              distribution = "multinomial",
              cv.folds = 10,
              shrinkage = .1,
              n.minobsinnode = 10,
              n.trees = 100) #reduce n.trees to increase sensitivity
pre <- predict(boost, newdata = X_test, type = "response", n.trees = 200)
pred <- pre[,,1][,1]
y_pred <- ifelse(as.numeric(pred)>0.5,0,1)
confusionMatrix(as.factor(y_pred), as.factor(y_test))
plot_roc(as.numeric(y_pred))
```

```{r}
#pca, not balanced TERRIBLE
data_bn = X_train_pca
data_bn$y = y_train

boost=gbm(y ~.,
              data = data_bn,
              distribution = "multinomial",
              cv.folds = 10,
              shrinkage = .3,
              n.minobsinnode = 10,
              n.trees = 50) #reduce n.trees to increase sensitivity
pre <- predict(boost, newdata = X_test_pca, type = "response", n.trees = 200)
pred <- pre[,,1][,1]
y_pred <- ifelse(as.numeric(pred)>0.7,0,1)
confusionMatrix(as.factor(y_pred), as.factor(y_test))
```

```{r}
#pca,balanced emmm
data_bb = X_train_balanced_pca
data_bb$y = y_train_balanced

boost=gbm(y ~.,
              data = data_bb,
              distribution = "multinomial",
              cv.folds = 10,
              shrinkage = .01,
              n.minobsinnode = 10,
              n.trees = 100) #reduce n.trees to increase sensitivity
pre <- predict(boost, newdata = X_test_pca, type = "response", n.trees = 200)
pred <- pre[,,1][,1]
y_pred <- ifelse(as.numeric(pred)>0.5,0,1)
confusionMatrix(as.factor(y_pred), as.factor(y_test))
```
##SVM
```{r}
# SVM PCA, balanced: sensitivity 0.76, specificity 0.65, roc 0.71 Normal-Good

svm <- train(y ~., data = data_bb, method = 'svmLinearWeights2', trControl = trainControl("repeatedcv", number = 10), preProcess = c("center","scale") )


pre_svm <- predict(svm, X_test_balanced_pca)

confusionMatrix(pre_svm, y_test, positive = "1")
plot_roc(as.numeric(pre_svm))

```

```{r}
# SVM PCA, not balanced: sensitivity 0.01, specificity 1, roc 0.51 Very Bad


svm <- train(y ~., data = data_bn, method = 'svmLinearWeights2', trControl = trainControl("repeatedcv", number = 10), preProcess = c("center","scale") )


pre_svm <- predict(svm, X_test_pca)

confusionMatrix(pre_svm,y_test, positive = "1")
plot_roc(as.numeric(pre_svm))
```

```{r}
# SVM not PCA, balanced: sensitivity 0.78, specificity 0.70, roc 0.74 Good

svm <- train(y ~., data = data_nb, method = 'svmLinear', trControl = trainControl("repeatedcv", number = 10), preProcess = c("center","scale") )


pre_svm <- predict(svm, X_test)

confusionMatrix(pre_svm,y_test, positive = "1")
plot_roc(as.numeric(pre_svm))
```

```{r}
# SVM not PCA, not balanced: sensitivity 0.1, specificity 0.98, roc 0.55 Very Bad

svm <- train(y ~., data = data_nn, method = 'svmLinearWeights2', trControl = trainControl("repeatedcv", number = 10), preProcess = c("center","scale") )


pre_svm <- predict(svm, X_test)

confusionMatrix(pre_svm,y_test, positive = "1")
plot_roc(as.numeric(pre_svm))

```


## KNN
```{r}
library(class)

# KNN pca, balanced: sensitivity 0.73, specificity 0.61, roc 0.67 Normal-Good

pre_knn <- knn(X_train_balanced_pca, X_test_balanced_pca , cl = y_train_balanced, k = 18, l = 0, prob = FALSE, use.all = TRUE)

confusionMatrix(pre_knn, y_test, positive = "1")
plot_roc(as.numeric(pre_knn))
```

```{r}
# KNN not pca, balanced: sensitivity 0.34, specificity 0.7, roc 0.52 Bad-Normal

pre_knn <- knn(X_train_balanced, X_test , cl = y_train_balanced, k = 2, l = 0, prob = FALSE, use.all = TRUE)

confusionMatrix(pre_knn, y_test, positive = "1")
plot_roc(as.numeric(pre_knn))
```

```{r}
# KNN pca, not balanced: sensitivity 0.21, specificity 0.86, roc 0.54 Very bad

pre_knn <- knn(X_train_pca, X_test_pca , cl = y_train, k = 2, l = 0, prob = FALSE, use.all = TRUE)

confusionMatrix(pre_knn, y_test, positive = "1")
plot_roc(as.numeric(pre_knn))
```

```{r}
# KNN not pca, not balanced: sensitivity 0.2, specificity 0.83, roc 0.51 Very Bad

pre_knn <- knn(X_train, X_test, cl = y_train, k = 2, l = 0, prob = FALSE, use.all = TRUE)

confusionMatrix(pre_knn, y_test, positive = "1")
plot_roc(as.numeric(pre_knn))
```


## Oversampling vs PCA
## Shiny app
